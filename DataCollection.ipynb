{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766afd68",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b13b01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ Seed videos already exist. Skipping new video collection.\n",
      "ðŸ“Š Updating engagement snapshots (one per video per day, up to 7 days)...\n",
      "âš ï¸ No stats returned for video_id=HY1Rd-B3y-Q\n",
      "âš ï¸ No stats returned for video_id=P8aqzsVTAeQ\n",
      "âš ï¸ No stats returned for video_id=ol30GkzEnjA\n",
      "âš ï¸ No stats returned for video_id=8fzzEXyJJDg\n",
      "âš ï¸ No stats returned for video_id=aSNb7DdI39g\n",
      "âš ï¸ No stats returned for video_id=6RAIxSCHBrs\n",
      "âš ï¸ No stats returned for video_id=My2Bzh6rZUM\n",
      "âš ï¸ No stats returned for video_id=6tyCVWdxx6Q\n",
      "âš ï¸ No stats returned for video_id=wLIIagoWGb8\n",
      "âš ï¸ No stats returned for video_id=r789iCf6NR0\n",
      "âš ï¸ No stats returned for video_id=DqrTg6KVCE8\n",
      "âš ï¸ No stats returned for video_id=1eQUW8g8PgQ\n",
      "âš ï¸ No stats returned for video_id=USDqFyn8UPA\n",
      "âš ï¸ No stats returned for video_id=qiH0YbSWNGg\n",
      "âš ï¸ No stats returned for video_id=_1YZvGPgLFE\n",
      "âš ï¸ No stats returned for video_id=DmOkTjAp79I\n",
      "âš ï¸ No stats returned for video_id=UZND5UyN4DU\n",
      "âš ï¸ No stats returned for video_id=WvKR0Sdo4pc\n",
      "âš ï¸ No stats returned for video_id=qc9xRPVKIes\n",
      "âš ï¸ No stats returned for video_id=E7ImnPzwoL0\n",
      "âš ï¸ No stats returned for video_id=vxiD6osSKEs\n",
      "âš ï¸ No stats returned for video_id=ZHbLQdJViYE\n",
      "âš ï¸ No stats returned for video_id=aqwcc5dHQ_A\n",
      "âš ï¸ No stats returned for video_id=V-1ExvYZrKY\n",
      "âš ï¸ No stats returned for video_id=VpSu-GHbKG4\n",
      "âš ï¸ No stats returned for video_id=Qwu44aA0nOQ\n",
      "âš ï¸ No stats returned for video_id=ETP4oToLkKM\n",
      "âš ï¸ No stats returned for video_id=-N8mdo_F_gI\n",
      "âš ï¸ No stats returned for video_id=367X40KMGw4\n",
      "âš ï¸ No stats returned for video_id=2tYcC_nl5uc\n",
      "âš ï¸ No stats returned for video_id=sULD_eHjhCo\n",
      "âš ï¸ No stats returned for video_id=w7a4Qw3YCek\n",
      "âš ï¸ No stats returned for video_id=aL5abobPw6s\n",
      "âš ï¸ No stats returned for video_id=N--3YQKYavg\n",
      "âš ï¸ No stats returned for video_id=3bUsm57tMDA\n",
      "âš ï¸ No stats returned for video_id=rSCafW0L_eg\n",
      "âš ï¸ No stats returned for video_id=9RjBxdlX5rA\n",
      "âš ï¸ No stats returned for video_id=VVLTGpQh5YE\n",
      "âš ï¸ No stats returned for video_id=48zTySnCTcY\n",
      "âš ï¸ No stats returned for video_id=Sky8b92qYXw\n",
      "âš ï¸ No stats returned for video_id=KOiM3VSIj5E\n",
      "âš ï¸ No stats returned for video_id=07COpNjs4Ak\n",
      "âš ï¸ No stats returned for video_id=5YzYN9JEK5c\n",
      "âš ï¸ No stats returned for video_id=gYvNr9ByIvM\n",
      "âš ï¸ No stats returned for video_id=9WWc8JqRXDU\n",
      "âš ï¸ No stats returned for video_id=qzHQxQSx5FQ\n",
      "âš ï¸ No stats returned for video_id=qlWdrpjqqMw\n",
      "âš ï¸ No stats returned for video_id=f58yS5soCls\n",
      "âš ï¸ No stats returned for video_id=cH5AzCJ1Yns\n",
      "âš ï¸ No stats returned for video_id=zSH7Ud6F6Kk\n",
      "âš ï¸ No stats returned for video_id=fmj15Nl6dJ0\n",
      "âš ï¸ No stats returned for video_id=jC6RBmZwu_U\n",
      "âš ï¸ No stats returned for video_id=-gKSmHdGL-M\n",
      "âš ï¸ No stats returned for video_id=nUrsRRMjp3I\n",
      "âš ï¸ No stats returned for video_id=DyORl1nWjuo\n",
      "âš ï¸ No stats returned for video_id=O4gtiSkW2ro\n",
      "ðŸ“¥ Added 2758 snapshot(s). Saved to engagement_snapshots_16.csv\n",
      "âœ… Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "YouTube Engagement Snapshot Collector\n",
    "-------------------------------------\n",
    "Run once per day.\n",
    "\n",
    "First run\n",
    "  - Collect videos from the last 24 hours for SEARCH_QUERIES\n",
    "\n",
    "Subsequent runs (days 1..7):\n",
    "  - Append one engagement snapshot per day (views/likes/comments/timestamp)\n",
    "    for the original set of videos, up to 7 days since publish\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "API_KEY = 'AIzaSyBBGSADyqTlyuc7svXh9XMDyekaf2i_IM8'\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "SEARCH_QUERIES = [\n",
    "    \"unboxing\", \"sponsored\", \"review\", \"haul\",\n",
    "    \"TikTok made me buy it\", \"giveaway\", \"product launch\", \"viral ad\"\n",
    "]\n",
    "\n",
    "VIDEO_FILE = \"youtube_videos_16.csv\"\n",
    "SNAPSHOT_FILE = \"engagement_snapshots_16.csv\"\n",
    "\n",
    "# Max days we keep taking snapshots for a video after publish\n",
    "SNAPSHOT_DAYS = 7\n",
    "\n",
    "# API safety: small delay between calls to reduce rate-limit risk\n",
    "API_DELAY_SECS = 0.1\n",
    "\n",
    "\n",
    "def get_today_bounds():\n",
    "    \"\"\"Return ISO timestamps for the last 24 hours (UTC).\"\"\"\n",
    "    now = datetime.now(timezone.utc)\n",
    "    yesterday = now - timedelta(days=1)\n",
    "    return yesterday.isoformat(), now.isoformat()\n",
    "\n",
    "\n",
    "def fetch_new_videos(query, published_after, published_before):\n",
    "    \"\"\"Search for videos by query within a 24h window (UTC).\"\"\"\n",
    "    video_ids = []\n",
    "    next_page_token = None\n",
    "    while True:\n",
    "        request = youtube.search().list(\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            part=\"id\",\n",
    "            maxResults=50,\n",
    "            publishedAfter=published_after,\n",
    "            publishedBefore=published_before,\n",
    "            order=\"date\",\n",
    "            pageToken=next_page_token,\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response.get(\"items\", []):\n",
    "            vid = item[\"id\"][\"videoId\"]\n",
    "            video_ids.append(vid)\n",
    "\n",
    "        next_page_token = response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        time.sleep(API_DELAY_SECS)\n",
    "\n",
    "    return list(set(video_ids))\n",
    "\n",
    "\n",
    "def fetch_channel_stats(channel_ids):\n",
    "    \"\"\"\n",
    "    Fetch channel-level statistics (subscriberCount, videoCount) ONCE for the seed.\n",
    "    Returns DataFrame: channel_id, channel_subscriber_count, channel_video_count.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i in range(0, len(channel_ids), 50):\n",
    "        chunk = channel_ids[i : i + 50]\n",
    "        resp = youtube.channels().list(\n",
    "            part=\"statistics\",\n",
    "            id=\",\".join(chunk),\n",
    "            maxResults=50,\n",
    "        ).execute()\n",
    "\n",
    "        for item in resp.get(\"items\", []):\n",
    "            ch_id = item[\"id\"]\n",
    "            stats = item.get(\"statistics\", {}) or {}\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"channel_id\": ch_id,\n",
    "                    \"channel_subscriber_count\": stats.get(\"subscriberCount\"),\n",
    "                    \"channel_video_count\": stats.get(\"videoCount\"),\n",
    "                }\n",
    "            )\n",
    "        time.sleep(API_DELAY_SECS)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df.drop_duplicates(subset=[\"channel_id\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_video_details(video_ids):\n",
    "    \"\"\"\n",
    "    Get snippet, statistics, contentDetails for a list of video IDs for the seed set.\n",
    "    Also enrich with channel stats (subscriber/video counts) and save ONLY in VIDEO_FILE.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    channel_ids = set()\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        chunk = video_ids[i : i + 50]\n",
    "        response = youtube.videos().list(\n",
    "            part=\"snippet,statistics,contentDetails\",\n",
    "            id=\",\".join(chunk),\n",
    "        ).execute()\n",
    "\n",
    "        for item in response.get(\"items\", []):\n",
    "            vid = item[\"id\"]\n",
    "            snippet = item.get(\"snippet\", {}) or {}\n",
    "            stats = item.get(\"statistics\", {}) or {}\n",
    "            content = item.get(\"contentDetails\", {}) or {}\n",
    "\n",
    "            publish_time = pd.to_datetime(snippet.get(\"publishedAt\"))\n",
    "            ch_id = snippet.get(\"channelId\")\n",
    "            if ch_id:\n",
    "                channel_ids.add(ch_id)\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"video_id\": vid,\n",
    "                    \"title\": snippet.get(\"title\"),\n",
    "                    \"description\": snippet.get(\"description\"),\n",
    "                    \"tags\": \"|\".join(snippet.get(\"tags\", [])) if snippet.get(\"tags\") else \"\",\n",
    "                    \"category_id\": snippet.get(\"categoryId\"),\n",
    "                    \"duration\": content.get(\"duration\"),\n",
    "                    \"publish_time\": publish_time,\n",
    "                    \"channel_id\": ch_id,\n",
    "                    \"channel_title\": snippet.get(\"channelTitle\"),\n",
    "                    # seed-time stats (strings from API; will coerce below)\n",
    "                    \"view_count\": stats.get(\"viewCount\"),\n",
    "                    \"like_count\": stats.get(\"likeCount\"),\n",
    "                    \"comment_count\": stats.get(\"commentCount\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        time.sleep(API_DELAY_SECS)\n",
    "\n",
    "    videos_df = pd.DataFrame(rows)\n",
    "    if videos_df.empty:\n",
    "        return videos_df\n",
    "\n",
    "    videos_df.drop_duplicates(subset=[\"video_id\"], inplace=True)\n",
    "\n",
    "    # Merge channel stats once\n",
    "    if channel_ids:\n",
    "        ch_stats_df = fetch_channel_stats(list(channel_ids))\n",
    "        videos_df = videos_df.merge(ch_stats_df, on=\"channel_id\", how=\"left\")\n",
    "\n",
    "    return videos_df\n",
    "\n",
    "\n",
    "def load_csv_or_empty(path, parse_dates=None):\n",
    "    if os.path.exists(path):\n",
    "        return pd.read_csv(path, parse_dates=parse_dates)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def coerce_stats_to_int(df, cols):\n",
    "    \"\"\"YouTube API returns numbers as strings; coerce safely.\"\"\"\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def update_snapshots(videos_df, snapshots_df):\n",
    "\n",
    "    if videos_df.empty:\n",
    "        print(\"No videos to snapshot.\")\n",
    "        return snapshots_df, 0\n",
    "\n",
    "    now = datetime.now(timezone.utc)\n",
    "    videos_df[\"publish_time\"] = pd.to_datetime(videos_df[\"publish_time\"], utc=True)\n",
    "\n",
    "    # Only videos within the allowed snapshot window\n",
    "    videos_df[\"days_since_publish\"] = (now - videos_df[\"publish_time\"]).dt.days\n",
    "    active = videos_df[videos_df[\"days_since_publish\"].between(0, SNAPSHOT_DAYS)]\n",
    "\n",
    "    if active.empty:\n",
    "        print(\"No active videos within snapshot window.\")\n",
    "        return snapshots_df, 0\n",
    "\n",
    "    # Ensure snapshots_df has key columns\n",
    "    if snapshots_df.empty:\n",
    "        snapshots_df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"video_id\",\n",
    "                \"snapshot_day\",\n",
    "                \"view_count\",\n",
    "                \"like_count\",\n",
    "                \"comment_count\",\n",
    "                \"timestamp\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Build a set of existing (video_id, snapshot_day) to avoid duplicates\n",
    "    existing_pairs = set()\n",
    "    if not snapshots_df.empty:\n",
    "        existing_pairs = set(\n",
    "            zip(\n",
    "                snapshots_df[\"video_id\"].astype(str),\n",
    "                snapshots_df[\"snapshot_day\"].astype(int),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    new_rows = []\n",
    "    for _, row in active.iterrows():\n",
    "        video_id = str(row[\"video_id\"])\n",
    "        snapshot_day = int(row[\"days_since_publish\"])\n",
    "\n",
    "        # Skip if today's snapshot already exists\n",
    "        if (video_id, snapshot_day) in existing_pairs:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            resp = youtube.videos().list(part=\"statistics\", id=video_id).execute()\n",
    "            items = resp.get(\"items\", [])\n",
    "            if not items:\n",
    "                print(f\" No stats returned for video_id={video_id}\")\n",
    "                continue\n",
    "\n",
    "            stats = items[0].get(\"statistics\", {}) or {}\n",
    "\n",
    "            new_rows.append(\n",
    "                {\n",
    "                    \"video_id\": video_id,\n",
    "                    \"snapshot_day\": snapshot_day,\n",
    "                    \"view_count\": stats.get(\"viewCount\"),\n",
    "                    \"like_count\": stats.get(\"likeCount\"),\n",
    "                    \"comment_count\": stats.get(\"commentCount\"),\n",
    "                    \"timestamp\": now.isoformat(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            time.sleep(API_DELAY_SECS)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error fetching stats for video_id={video_id}: {e}\")\n",
    "\n",
    "    if not new_rows:\n",
    "        print(\"â„¹ï¸ No new snapshots to add today.\")\n",
    "        return snapshots_df, 0\n",
    "\n",
    "    updates_df = pd.DataFrame(new_rows)\n",
    "    updates_df = coerce_stats_to_int(\n",
    "        updates_df, [\"view_count\", \"like_count\", \"comment_count\"]\n",
    "    )\n",
    "    snapshots_df = pd.concat([snapshots_df, updates_df], ignore_index=True)\n",
    "\n",
    "    # Deduplicate safety\n",
    "    snapshots_df.drop_duplicates(subset=[\"video_id\", \"snapshot_day\"], keep=\"last\", inplace=True)\n",
    "    return snapshots_df, len(updates_df)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load or initialize storage\n",
    "    videos_df = load_csv_or_empty(VIDEO_FILE, parse_dates=[\"publish_time\"])\n",
    "    snapshots_df = load_csv_or_empty(SNAPSHOT_FILE)\n",
    "\n",
    "    if videos_df.empty:\n",
    "        # ======================= DAY 0: SEED COLLECTION =======================\n",
    "        print(\"ðŸ” First run detected: collecting videos from the last 24 hours...\")\n",
    "        published_after, published_before = get_today_bounds()\n",
    "\n",
    "        all_ids = set()\n",
    "        for q in SEARCH_QUERIES:\n",
    "            ids = fetch_new_videos(q, published_after, published_before)\n",
    "            all_ids.update(ids)\n",
    "        all_ids = list(all_ids)\n",
    "        print(f\"âœ… Found {len(all_ids)} new video(s) to seed.\")\n",
    "\n",
    "        if all_ids:\n",
    "            new_videos_df = fetch_video_details(all_ids)\n",
    "\n",
    "            # Coerce numeric stats for both video and channel fields (seed only)\n",
    "            new_videos_df = coerce_stats_to_int(\n",
    "                new_videos_df,\n",
    "                [\n",
    "                    \"view_count\",\n",
    "                    \"like_count\",\n",
    "                    \"comment_count\",\n",
    "                    \"channel_subscriber_count\",\n",
    "                    \"channel_video_count\",\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # Save seed set with channel stats\n",
    "            new_videos_df.to_csv(VIDEO_FILE, index=False)\n",
    "            videos_df = new_videos_df\n",
    "            print(f\" Saved {len(new_videos_df)} video(s) to {VIDEO_FILE}\")\n",
    "        else:\n",
    "            print(\" No videos found for seeding. Exiting.\")\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        print(\"â„¹ï¸ Seed videos already exist. Skipping new video collection.\")\n",
    "\n",
    "    # ======================= DAYS 0..7: SNAPSHOTS ONLY =======================\n",
    "    print(\" Updating engagement snapshots (one per video per day, up to 7 days)...\")\n",
    "    snapshots_df, added = update_snapshots(videos_df, snapshots_df)\n",
    "\n",
    "    if added > 0:\n",
    "        snapshots_df.to_csv(SNAPSHOT_FILE, index=False)\n",
    "        print(f\"Added {added} snapshot(s). Saved to {SNAPSHOT_FILE}\")\n",
    "    else:\n",
    "        print(\"No snapshots added today.\")\n",
    "\n",
    "    print(\" Done\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f2fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
